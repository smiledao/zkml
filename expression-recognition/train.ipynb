{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:21:08.193921900Z",
     "start_time": "2023-06-24T19:21:07.247507400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ExpressionDataset import ExpressionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3090 Ti\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "image_size = 96\n",
    "mean = [0.5375, 0.4315, 0.3818]\n",
    "std = [0.2928, 0.2656, 0.2614]\n",
    "\n",
    "epochs = 500"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:21:08.257160400Z",
     "start_time": "2023-06-24T19:21:08.220063700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "dataset = ExpressionDataset('./data/', transform=transform)\n",
    "dataset = [dataset[i] for i in torch.randperm(len(dataset))]\n",
    "train_len = int(len(dataset) * 0.8)\n",
    "val_len = len(dataset) - train_len\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_len, val_len])\n",
    "train_dl = DataLoader(train_dataset, batch_size=16, num_workers=8)\n",
    "val_dl = DataLoader(val_dataset, batch_size=128, num_workers=8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:21:24.427985200Z",
     "start_time": "2023-06-24T19:21:08.229160100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "# Using a pretrained (open source) model for the sake of time\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2)\n",
    "model.set_swish(memory_efficient=False)\n",
    "model = model.to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:21:24.632329200Z",
     "start_time": "2023-06-24T19:21:24.429985100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:21:24.661634900Z",
     "start_time": "2023-06-24T19:21:24.634328Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer):\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    for images, labels in tqdm(train_dl):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += torch.sum(predictions == labels.data)\n",
    "\n",
    "    return train_loss / len(train_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:21:24.668634900Z",
     "start_time": "2023-06-24T19:21:24.649428800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_correct += torch.sum(predictions == labels.data)\n",
    "            label_list = np.concatenate([label_list, labels.cpu()])\n",
    "            pred_list = np.concatenate([pred_list, predictions.cpu()])\n",
    "\n",
    "    val_accuracy = (100.0 * val_correct / len(loader.dataset)).cpu()\n",
    "    val_f1 = f1_score(label_list, pred_list)\n",
    "    val_roc_auc = roc_auc_score(label_list, pred_list)\n",
    "    val_recall = recall_score(label_list, pred_list)\n",
    "\n",
    "    return val_accuracy, val_recall, val_f1, val_roc_auc\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:21:25.215452200Z",
     "start_time": "2023-06-24T19:21:24.667636500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1453/1453 [01:43<00:00, 14.00it/s]\n",
      "100%|██████████| 1453/1453 [00:41<00:00, 35.09it/s]\n",
      "100%|██████████| 46/46 [00:23<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Best Performing Model...\n",
      "Epoch: 001, Loss: 0.20189\n",
      "Train Acc: 97.7962417602539, Train Recall: 0.9310770750988142, Train F1: 0.9363975155279504, Train ROC-AUC: 0.9594660851126074\n",
      "Val Acc: 96.07505798339844, Val Recall: 0.8664658634538153, Val F1: 0.8833162743091095, Val ROC-AUC: 0.9233638272182851\n",
      "Time: 168.30545 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1453/1453 [01:33<00:00, 15.50it/s]\n",
      "100%|██████████| 1453/1453 [00:49<00:00, 29.57it/s]\n",
      "100%|██████████| 46/46 [00:22<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 0.08632\n",
      "Train Acc: 98.40744018554688, Train Recall: 0.9214426877470355, Train F1: 0.9527458492975733, Train ROC-AUC: 0.9593661184369788\n",
      "Val Acc: 96.72920989990234, Val Recall: 0.857429718875502, Val F1: 0.8998946259220232, Val ROC-AUC: 0.9237283645281312\n",
      "Time: 165.72241 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1453/1453 [01:39<00:00, 14.66it/s]\n",
      "100%|██████████| 1453/1453 [00:40<00:00, 35.83it/s]\n",
      "100%|██████████| 46/46 [00:22<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Best Performing Model...\n",
      "Epoch: 003, Loss: 0.04247\n",
      "Train Acc: 99.19081115722656, Train Recall: 0.9807312252964426, Train F1: 0.9768700787401575, Train ROC-AUC: 0.987498789609389\n",
      "Val Acc: 96.98743438720703, Val Recall: 0.9136546184738956, Val F1: 0.9122807017543861, Val ROC-AUC: 0.9475815165920278\n",
      "Time: 162.30888 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1453/1453 [01:28<00:00, 16.33it/s]\n",
      "100%|██████████| 1453/1453 [00:38<00:00, 37.95it/s]\n",
      "100%|██████████| 46/46 [00:23<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Best Performing Model...\n",
      "Epoch: 004, Loss: 0.02981\n",
      "Train Acc: 99.18650817871094, Train Recall: 0.991600790513834, Train F1: 0.976998904709748, Train ROC-AUC: 0.9917607809749259\n",
      "Val Acc: 96.48820495605469, Val Recall: 0.929718875502008, Val F1: 0.9007782101167315, Val ROC-AUC: 0.9509388061283155\n",
      "Time: 150.33896 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1453/1453 [01:27<00:00, 16.70it/s]\n",
      "100%|██████████| 1453/1453 [00:41<00:00, 35.27it/s]\n",
      "100%|██████████| 46/46 [00:22<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Best Performing Model...\n",
      "Epoch: 005, Loss: 0.02128\n",
      "Train Acc: 99.1262435913086, Train Recall: 0.9930830039525692, Train F1: 0.9753730437947349, Train ROC-AUC: 0.9919806471417786\n",
      "Val Acc: 96.55706787109375, Val Recall: 0.9377510040160643, Val F1: 0.9032882011605416, Val ROC-AUC: 0.9545393291428753\n",
      "Time: 150.85913 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1453/1453 [01:24<00:00, 17.14it/s]\n",
      "100%|██████████| 1453/1453 [00:36<00:00, 39.47it/s]\n",
      "100%|██████████| 46/46 [00:21<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss: 0.01617\n",
      "Train Acc: 99.5523681640625, Train Recall: 0.9757905138339921, Train F1: 0.9870064967516242, Train ROC-AUC: 0.9877388847512416\n",
      "Val Acc: 96.86692810058594, Val Recall: 0.8594377510040161, Val F1: 0.9039070749736009, Val ROC-AUC: 0.9253556924560906\n",
      "Time: 143.07582 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1453 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train_hist = []\n",
    "val_hist = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    s = time.time()\n",
    "    loss = train(model, train_dl, criterion, optimizer)\n",
    "    train_acc, train_recall, train_f1, train_roc_auc = evaluate(model, train_dl)\n",
    "    val_acc, val_recall, val_f1, val_roc_auc = evaluate(model, val_dl)\n",
    "    scheduler.step(loss)\n",
    "    e = time.time()\n",
    "\n",
    "    train_hist.append((train_acc, train_recall, train_f1, train_roc_auc))\n",
    "    val_hist.append([val_recall])\n",
    "\n",
    "    if sum([val_recall]) >= np.asarray(val_hist).sum(axis=1).max():\n",
    "        print(\"Saving Best Performing Model...\")\n",
    "        torch.save(model.state_dict(), './models/BestModel.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.05f}\\n'\n",
    "          f'Train Acc: {train_acc}, Train Recall: {train_recall}, Train F1: {train_f1}, Train ROC-AUC: {train_roc_auc}\\n'\n",
    "          f'Val Acc: {val_acc}, Val Recall: {val_recall}, Val F1: {val_f1}, Val ROC-AUC: {val_roc_auc}\\n'\n",
    "          f'Time: {e - s:.05f} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-24T19:21:25.218451900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "example_input = torch.randn(1, 3, 96, 96).cuda()\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model,                     # model being run\n",
    "                  example_input,             # model input (or a tuple for multiple inputs)\n",
    "                  \"./models/model.onnx\",     # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names=['input'],     # the model's input names\n",
    "                  output_names=['output'],   # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
