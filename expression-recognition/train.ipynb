{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:08:38.288529700Z",
     "start_time": "2023-06-24T19:08:37.241497400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ExpressionDataset import ExpressionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3090 Ti\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "image_size = 96\n",
    "mean = [0.5375, 0.4315, 0.3818]\n",
    "std = [0.2928, 0.2656, 0.2614]\n",
    "\n",
    "epochs = 500"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:08:38.334904400Z",
     "start_time": "2023-06-24T19:08:38.290613100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])\n",
    "\n",
    "dataset = ExpressionDataset('./data/', transform=transform)\n",
    "dataset = [dataset[i] for i in torch.randperm(len(dataset))]\n",
    "train_len = int(len(dataset) * 0.8)\n",
    "val_len = len(dataset) - train_len\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_len, val_len])\n",
    "train_dl = DataLoader(train_dataset, batch_size=16, num_workers=8)\n",
    "val_dl = DataLoader(val_dataset, batch_size=128, num_workers=8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:08:53.823730800Z",
     "start_time": "2023-06-24T19:08:38.322805Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "# Using a pretrained (open source) model for the sake of time\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2)\n",
    "model.set_swish(memory_efficient=False)\n",
    "model = model.to('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:08:54.026336300Z",
     "start_time": "2023-06-24T19:08:53.826231300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:08:54.055678700Z",
     "start_time": "2023-06-24T19:08:54.029338400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer):\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "\n",
    "    for images, labels in tqdm(train_dl):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += torch.sum(predictions == labels.data)\n",
    "\n",
    "    return train_loss / len(train_dl)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:08:54.063768500Z",
     "start_time": "2023-06-24T19:08:54.044595300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, recall_score\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_correct += torch.sum(predictions == labels.data)\n",
    "            label_list = np.concatenate([label_list, labels.cpu()])\n",
    "            pred_list = np.concatenate([pred_list, predictions.cpu()])\n",
    "\n",
    "    val_accuracy = (100.0 * val_correct / len(loader.dataset)).cpu()\n",
    "    val_f1 = f1_score(label_list, pred_list)\n",
    "    val_roc_auc = roc_auc_score(label_list, pred_list)\n",
    "    val_recall = recall_score(label_list, pred_list)\n",
    "\n",
    "    return val_accuracy, val_recall, val_f1, val_roc_auc\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:08:54.557385300Z",
     "start_time": "2023-06-24T19:08:54.061768800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1453/1453 [01:29<00:00, 16.30it/s]\n",
      "100%|██████████| 1453/1453 [00:38<00:00, 37.85it/s]\n",
      "100%|██████████| 46/46 [00:22<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Best Performing Model...\n",
      "Epoch: 001, Loss: 0.08416\n",
      "Train Acc: 98.74317169189453, Train Recall: 0.9698914116485686, Train F1: 0.964180569185476, Train ROC-AUC: 0.9805142371834419\n",
      "Val Acc: 97.21122741699219, Val Recall: 0.9112903225806451, Val F1: 0.917766497461929, Val ROC-AUC: 0.9479640319567124\n",
      "Time: 150.15731 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1453/1453 [01:26<00:00, 16.82it/s]\n",
      " 70%|███████   | 1023/1453 [00:31<00:04, 94.11it/s]"
     ]
    }
   ],
   "source": [
    "train_hist = []\n",
    "val_hist = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    s = time.time()\n",
    "    loss = train(model, train_dl, criterion, optimizer)\n",
    "    train_acc, train_recall, train_f1, train_roc_auc = evaluate(model, train_dl)\n",
    "    val_acc, val_recall, val_f1, val_roc_auc = evaluate(model, val_dl)\n",
    "    scheduler.step(loss)\n",
    "    e = time.time()\n",
    "\n",
    "    train_hist.append((train_acc, train_recall, train_f1, train_roc_auc))\n",
    "    val_hist.append([val_recall])\n",
    "\n",
    "    if sum([val_recall]) >= np.asarray(val_hist).sum(axis=1).max():\n",
    "        print(\"Saving Best Performing Model...\")\n",
    "        torch.save(model.state_dict(), './models/BestModel.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.05f}\\n'\n",
    "          f'Train Acc: {train_acc}, Train Recall: {train_recall}, Train F1: {train_f1}, Train ROC-AUC: {train_roc_auc}\\n'\n",
    "          f'Val Acc: {val_acc}, Val Recall: {val_recall}, Val F1: {val_f1}, Val ROC-AUC: {val_roc_auc}\\n'\n",
    "          f'Time: {e - s:.05f} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-24T19:18:10.525403900Z",
     "start_time": "2023-06-24T19:12:08.504394600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "example_input = torch.randn(1, 3, 96, 96).cuda()\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model,                     # model being run\n",
    "                  example_input,             # model input (or a tuple for multiple inputs)\n",
    "                  \"./models/model.onnx\",     # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names=['input'],     # the model's input names\n",
    "                  output_names=['output'],   # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
